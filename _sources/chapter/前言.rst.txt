
前言
====

随着人工智能技术的迅猛发展，人工智能系统正被广泛应用于各行各业，以技术创新推动产业升级变革和高质量发展。然而，在取得高性能的同时，当前人工智能模型还存在诸多安全问题，如易受对抗样本攻击、易被安插后门、易泄露训练数据、模型参数易被抽取、被利用生成虚假信息等，带来严重的社会隐患。这些安全问题不仅威胁到系统的可靠性和稳定性，还可能导致用户隐私泄露、数据滥用以及信息安全风险。因此，深入研究并解决这些安全问题，是确保我国人工智能产业安全、可靠、可控发展的关键。

本书《大模型安全》正是在这一背景下编写的。大模型安全关注的是大模型本身的内在安全问题，具体是指大模型在数据收集、模型训练、下游微调及部署应用等生命周期中各环节所面临的安全风险。针对这些风险，本书从介绍基于传统小模型设计的基础攻击和防御算法出发，深入探讨了当前大模型所面临的各类新型攻击以及可能的防御方法。

进入大模型时代，人工智能领域迎来了新的挑战。大模型在性能和能力上显著提升，但也带来了新的安全隐患。与传统小模型相比，大模型的复杂性和规模使得以前设计的攻防方法不再适用。我们需要重新审视并设计适用于大模型的安全策略和技术。显然，单纯依赖旧有的安全措施已无法满足当前的需求，新的攻防算法和防护机制亟待研发和应用。

在编写本书的过程中，我们发现国内关于大模型安全的教材仍然存在空白。这一现状促使我们专注于大模型的安全问题，对目前最前沿的研究进展进行系统梳理。书中内容覆盖了视觉大模型、大语言模型和多模态大模型三类主流模型的各类攻击方法和防御策略。这些介绍不仅填补了现有文献的空白，也为相关领域的研究人员和从业者提供了重要的参考和指导。

本书将之前针对小模型的研究总结为“攻击算法基础”和“防御算法基础”两个基础章节，并通过三个进阶章节——“视觉大模型安全”、“大语言模型安全”和“多模态大模型安全”——全面介绍大模型的安全研究。这些章节不仅涵盖了当前大模型面临的主要安全威胁，还探讨了最前沿的攻防技术，旨在为大模型的未来安全可靠发展提供理论支撑和实践指南。

我们编写本书的使命感和责任感来自于对人工智能安全领域的深刻认识。我们希望通过本书的系统性总结和深入探讨，促进人工智能领域的健康发展，并为相关研究和应用提供有价值的参考。我们的目标不仅是推动理论研究的进步，更是为实践中的问题提供切实可行的解决方案。

在未来的道路上，我们将继续坚持科技创新，注重安全防护，为建设一个更加智能、安全和美好的世界贡献力量。让我们携手并肩，为人工智能的安全研究和应用开创新的篇章，为人类社会的进步和繁荣做出应有的贡献。

本书适合人工智能、计算机科学与技术、软件工程、信息安全等相关专业的本科生、研究生及从业者阅读。部分技术细节较为复杂，读者需要具备一定的机器学习基础并对大模型相关技术有一定了解。

最后，感谢复旦大学视觉与学习实验室的同学们在本书编写和校稿过程中提供的协助，包括（按姓氏首字母排序）：陈云豪、高翌峰、黄叙彬、罗林、林嘉濠、李潇、曲志久、苏红宇、孙野、宋天伟、王若凡、王熠旭、王欣、王智祥、谢勇、张家豪、赵蕴涵、郑伟杰等。

由于作者水平有限，本书难免存在不足之处，恳请各位老师和同学给予宝贵的建议和指导。

.. raw:: html

    <div style="text-align: right; margin-top: 25px;">
        姜育刚
        <p></p>
        2024年7月于复旦大学
    </div>
